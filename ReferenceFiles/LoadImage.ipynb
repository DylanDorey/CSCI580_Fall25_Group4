{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PyTorch to Set Up MNIST Dataset for Training\n",
    "\n",
    "After you have successfully installed PyTorch, you can use the sample code to load the MNIST dataset.\n",
    "You will use this dataset for training your neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Images\n",
    "\n",
    "MNIST dataset consists of images of greyscale handwritten digits. Each image is 28x28 pixels, you can see a sample below\n",
    "\n",
    "<img src='mnist.png'>\n",
    "\n",
    "Our goal is to build a neural network that can take one of these images and predict the digit in the image.\n",
    "\n",
    "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. The dataset's name is MNIST, this code downloads that dataset to a local folder of your choice, in this example, it is ~/.pytorch/MNIST_dadta/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datasets and Batches\n",
    "\n",
    "We have the training data loaded into `trainset`, and the dataset is loaded batches (`trainloader`). We make that an iterator with `iter(trainloader)`. Later, we'll use this to loop through the dataset for training, like\n",
    "\n",
    "```python\n",
    "for image, label in trainloader:\n",
    "    ## do things with images and labels\n",
    "```\n",
    "\n",
    "You'll notice I created the `trainloader` with a batch size of 64, and `shuffle=True`. The batch size is the number of images we get in one iteration from the data loader and pass through our network, often called a *batch*. And `shuffle=True` tells it to shuffle the dataset every time we start going through the data loader again. But here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size `(64, 1, 28, 28)`. So there are 64 images per batch, with every image having 1 color channel(monochrom, gray scale), and of size 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of images in the trainset:', len(trainset))\n",
    "print('Total number of batches:', len(trainloader))\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.__next__()\n",
    "print('Data type of images:', type(images))\n",
    "print('Shape of images:', images.shape)\n",
    "print('Shape of labels:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize the Images\n",
    "\n",
    "This is what one of the images looks like. `i` can be 0 to 63, play with it to take a look at some other images in this batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "print(labels[i])\n",
    "#print(images[i])\n",
    "print(images[i].flatten().shape)\n",
    "print(torch.flatten(images[i]).shape)\n",
    "print(images.view(images.shape[0], -1).shape)\n",
    "plt.imshow(images[i].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. More Experiments with DataLoader\n",
    "\n",
    "DataLoader is the PyTorch API that prepares the traning data (`trainloader`) for us.\n",
    "\n",
    "Here is more about DataLoader. Try to play with this code, find out:\n",
    "- How to control the total number of images you want to use for training\n",
    "- How to configure the batch size\n",
    "- Any other ways you want to use the DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in trainloader:\n",
    "    print('images.shape: {}, labels.shape: {}'.format(images.shape, labels.shape))\n",
    "    break;\n",
    "\n",
    "# The following is to illustrate the use of dataloader, with batch_size and drop_last\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.x = torch.randn(size, 1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "dataset = MyDataset(1001)\n",
    "data_loader = DataLoader(dataset, batch_size=10)\n",
    "len(data_loader)\n",
    "for batch_idx, data in enumerate(data_loader):\n",
    "    if (batch_idx>95):\n",
    "        print ('batch idx{}, batch len {}'.format(batch_idx, len(data)))\n",
    "\n",
    "print ('Here is if we drop the last one while loading:')\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=10, drop_last=True)\n",
    "len(data_loader)\n",
    "for batch_idx, data in enumerate(data_loader):\n",
    "    if (batch_idx>95):\n",
    "        print ('batch idx{}, batch len {}'.format(batch_idx, len(data)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
